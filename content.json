{"pages":[{"title":"404","date":"2019-07-19T08:41:10.000Z","path":"404.html","text":"你来到了没有知识的荒原 :("},{"title":"关于","date":"2019-08-04T05:28:20.200Z","path":"about/index.html","text":"Email : yp_ren@126.com"},{"title":"分类","date":"2019-08-18T03:32:37.474Z","path":"categories/index.html","text":""},{"title":"标签","date":"2019-08-02T05:00:35.984Z","path":"tags/index.html","text":""}],"posts":[{"title":"Redis zset 实现简单限流","date":"2019-08-19T01:48:40.000Z","path":"wiki/Redis-zset-实现简单限流/","text":"除了控制流量，限流还有一个应用目的是用于控制用户行为，避免垃圾请求。比如在 UGC 社区，用户的发帖、回复、点赞等行为都要严格受控，一般要严格限定某行为在规定时间内允许的次数，超过了次数那就是非法行为。对非法行为，业务必须规定适当的惩处策略。 如何使用 Redis 来实现简单限流策略？首先我们来看一个常见的简单的限流策略。系统要限定用户的某个行为在指定的时间里只能允许发生 N 次，如何使用 Redis 的数据结构来实现这个限流的功能？ 我们先定义这个接口，理解了这个接口的定义，读者就应该能明白我们期望达到的功能。 // 指定用户 user_id 的某个行为 action_key，在特定的时间内 period，只允许发生一定的次数 max_countpublic boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) &#123;&#125;// 调用这个接口，5 分钟之内只能发帖 10 次limiter.isActionAllowed(\"xiaoming\", \"publish\", 5 * 60, 10) 错误方案 将 userId 和 actionKey 拼成 key，在第一次请求时设置 value 为 1，设置过期时间 expire 为特定的时间 period 每次请求的时候获取 value 值，若存在则 incr 自增 1，超过 maxCount 则做限制 问题模拟分析 如上图：5 分钟之内只能发帖 10 次。 11:01 用户发帖 1 次，此时 redis 中存放数据 key 为 userId:actionKey，vlaue 为 1，过期时间 5 分钟； 11:05 用户发帖 8 次，发帖成功； 11:05 之后，key 过期时间到，被移除； 11:06 用户发帖，此时 redis 中 key 不存在，重新存放 key，发帖 8 次，发帖成功； 那么 11:05 -&gt; 11:06 时间段 2 分钟发帖 16 次，没有达到期望的功能； 正确方案这个限流需求中存在一个滑动时间窗口，想想 zset 数据结构的 score 值，是不是可以通过 score 来圈出这个时间窗口来。而且我们只需要保留这个时间窗口，窗口之外的数据都可以砍掉。那这个 zset 的 value 填什么比较合适呢？它只需要保证唯一性即可，用 uuid 会比较浪费空间，那就改用毫秒时间戳吧。 如图所示，用一个 zset 结构记录用户的行为历史，每一个行为都会作为 zset 中的一个 key 保存下来。同一个用户同一种行为用一个 zset 记录。 为节省内存，我们只需要保留时间窗口内的行为记录，同时如果用户是冷用户，滑动时间窗口内的行为是空记录，那么这个 zset 就可以从内存中移除，不再占用空间。 通过统计滑动窗口内的行为数量与阈值 max_count 进行比较就可以得出当前的行为是否允许。用代码表示如下： public class SimpleRateLimiter &#123; private Jedis jedis; public SimpleRateLimiter(Jedis jedis) &#123; this.jedis = jedis; &#125; /** * @param userId 用户 user_id * @param actionKey 某个行为 * @param period 特定的时间内，单位秒 * @param maxCount 最大允许的次数 * @return */ public boolean isActionAllowed(String userId, String actionKey, int period, int maxCount) &#123; String key = String.format(\"hist:%s:%s\", userId, actionKey); // 毫秒时间戳 long nowTs = System.currentTimeMillis(); Pipeline pipe = jedis.pipelined(); // 用了multi，也就是事务，能保证一系列指令的原子顺序执行 pipe.multi(); // 存放数据，value 和 score 都使用毫秒时间戳 pipe.zadd(key, nowTs, \"\" + nowTs); // zremrangebyscore key min max 命令用于移除有序集中，指定分数（score）区间内的所有成员 // 移除时间窗口之前的数据，剩下的都是时间窗口之内的 Response&lt;Long&gt; longResponse = pipe.zremrangeByScore(key, 0, nowTs - period * 1000); // 相当于 count()，获取时间窗口内的行为数量 Response&lt;Long&gt; count = pipe.zcard(key); // 设置 zset 过期时间，避免冷用户持续占用内存 // 过期时间应该等于时间窗口的长度，再多宽限 1s pipe.expire(key, period + 1); pipe.exec(); pipe.close(); // 比较数量是否超标 return count.get() &lt;= maxCount; &#125; public static void main(String[] args) &#123; Jedis jedis = new Jedis(); SimpleRateLimiter limiter = new SimpleRateLimiter(jedis); for (int i = 0; i &lt; 20; i++) &#123; System.out.println(limiter.isActionAllowed(\"xiaoming\", \"publish\", 5 * 60, 10)); &#125; &#125;&#125; 缺点因为它要记录时间窗口内所有的行为记录，如果这个量很大，比如限定 60s 内操作不得超过 100w 次这样的参数，它是不适合做这样的限流的，因为会消耗大量的存储空间。","tags":[],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"redis","slug":"技术分享/redis","permalink":"https://yapengren.github.io/categories/技术分享/redis/"}]},{"title":"Redis 深度历险：核心原理与应用实践","date":"2019-08-18T03:26:40.000Z","path":"wiki/Redis-深度历险：核心原理与应用实践/","text":"基础：万丈高楼平地起 —— Redis 基础数据结构千里之行，始于足下。本节我们的学习目标是：快速理解并掌握 Redis 的基础知识。 由于本节内容是 Redis 最简单最容易掌握的知识，如果读者已经很熟悉 Redis 的基础数据结构，从珍惜生命的角度出发，你可以略过本节内容，跳到下一节继续阅读。如果你觉得本节的动画有点晃眼，阅读起来不那么舒服，可以看看作者的另一篇文章《Redis 数据结构基础教程》。 要体验 Redis，我们先从 Redis 安装说起。 Redis 安装体验 Redis 需要使用 Linux 或者 Mac 环境，如果是 Windows 可以考虑使用虚拟机。主要方式有四种： 使用 Docker 安装。 通过 Github 源码编译。 直接安装 apt-get install(Ubuntu)、yum install(RedHat) 或者 brew install(Mac)。 如果读者懒于安装操作，也可以使用网页版的 Web Redis 直接体验。 具体操作如下： Docker 方式# 拉取 redis 镜像&gt; docker pull redis# 运行 redis 容器&gt; docker run --name myredis -d -p6379:6379 redis# 执行容器中的 redis-cli，可以直接使用命令行操作 redis&gt; docker exec -it myredis redis-cli Github 源码编译方式# 下载源码&gt; git clone --branch 2.8 --depth 1 git@github.com:antirez/redis.git&gt; cd redis# 编译&gt; make&gt; cd src# 运行服务器，daemonize表示在后台运行&gt; ./redis-server --daemonize yes# 运行命令行&gt; ./redis-cli 直接安装方式# mac&gt; brew install redis# ubuntu&gt; apt-get install redis# redhat&gt; yum install redis# 运行客户端&gt; redis-cli Redis 基础数据结构Redis 有 5 种基础数据结构，分别为：string (字符串)、list (列表)、set (集合)、hash (哈希) 和 zset (有序集合)。熟练掌握这 5 种基本数据结构的使用是 Redis 知识最基础也最重要的部分，它也是在 Redis 面试题中问到最多的内容。 本节将带领 Redis 初学者快速通关这 5 种基本数据结构。考虑到 Redis 的命令非常多，这里只选取那些最常见的指令进行讲解，如果有遗漏常见指令，读者可以在评论去留言。 string (字符串)字符串 string 是 Redis 最简单的数据结构。Redis 所有的数据结构都是以唯一的 key 字符串作为名称，然后通过这个唯一 key 值来获取相应的 value 数据。不同类型的数据结构的差异就在于 value 的结构不一样。 字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体使用 JSON 序列化成字符串，然后将序列化后的字符串塞进 Redis 来缓存。同样，取用户信息会经过一次反序列化的过程。 Redis 的字符串是动态字符串，是可以修改的字符串，内部结构实现上类似于 Java 的 ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配，如图中所示，内部为当前字符串实际分配的空间 capacity 一般要高于实际字符串长度 len。当字符串长度小于 1M 时，扩容都是加倍现有的空间，如果超过 1M，扩容时一次只会多扩 1M 的空间。需要注意的是字符串最大长度为 512M。 键值对 &gt; set name codeholeOK&gt; get name&quot;codehole&quot;&gt; exists name(integer) 1&gt; del name(integer) 1&gt; get name(nil) 批量键值对 可以批量对多个字符串进行读写，节省网络耗时开销。 &gt; set name1 codeholeOK&gt; set name2 holycoderOK&gt; mget name1 name2 name3 # 返回一个列表1) &quot;codehole&quot;2) &quot;holycoder&quot;3) (nil)&gt; mset name1 boy name2 girl name3 unknown&gt; mget name1 name2 name31) &quot;boy&quot;2) &quot;girl&quot;3) &quot;unknown&quot; 过期和 set 命令扩展 可以对 key 设置过期时间，到点自动删除，这个功能常用来控制缓存的失效时间。不过这个「自动删除」的机制是比较复杂的，如果你感兴趣，可以继续深入阅读第 26 节《朝生暮死——过期策略》 &gt; set name codehole&gt; get name&quot;codehole&quot;&gt; expire name 5 # 5s 后过期... # wait for 5s&gt; get name(nil)&gt; setex name 5 codehole # 5s 后过期，等价于 set+expire&gt; get name&quot;codehole&quot;... # wait for 5s&gt; get name(nil)&gt; setnx name codehole # 如果 name 不存在就执行 set 创建(integer) 1&gt; get name&quot;codehole&quot;&gt; setnx name holycoder(integer) 0 # 因为 name 已经存在，所以 set 创建不成功&gt; get name&quot;codehole&quot; # 没有改变 计数 如果 value 值是一个整数，还可以对它进行自增操作。自增是有范围的，它的范围是 signed long 的最大最小值，超过了这个值，Redis 会报错。 &gt; set age 30OK&gt; incr age(integer) 31&gt; incrby age 5(integer) 36&gt; incrby age -5(integer) 31&gt; set codehole 9223372036854775807 # Long.MaxOK&gt; incr codehole(error) ERR increment or decrement would overflow 字符串是由多个字节组成，每个字节又是由 8 个 bit 组成，如此便可以将一个字符串看成很多 bit 的组合，这便是 bitmap「位图」数据结构，位图的具体使用会放到后面的章节来讲。 关于字符串的内部结构实现，请阅读第 32 节《极度深寒 —— 探索「字符串」内部》 list (列表)Redis 的列表相当于 Java 语言里面的 LinkedList，注意它是链表而不是数组。这意味着 list 的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为 O(n)，这点让人非常意外。 当列表弹出了最后一个元素之后，该数据结构自动被删除，内存被回收。 Redis 的列表结构常用来做异步队列使用。将需要延后处理的任务结构体序列化成字符串塞进 Redis 的列表，另一个线程从这个列表中轮询数据进行处理。 右边进左边出：队列 &gt; rpush books python java golang(integer) 3&gt; llen books(integer) 3&gt; lpop books&quot;python&quot;&gt; lpop books&quot;java&quot;&gt; lpop books&quot;golang&quot;&gt; lpop books(nil) 右边进右边出：栈 &gt; rpush books python java golang(integer) 3&gt; rpop books&quot;golang&quot;&gt; rpop books&quot;java&quot;&gt; rpop books&quot;python&quot;&gt; rpop books(nil) 慢操作 lindex 相当于 Java 链表的get(int index)方法，它需要对链表进行遍历，性能随着参数index增大而变差。 ltrim 和字面上的含义不太一样，个人觉得它叫 lretain(保留) 更合适一些，因为 ltrim 跟的两个参数start_index和end_index定义了一个区间，在这个区间内的值，ltrim 要保留，区间之外统统砍掉。我们可以通过ltrim来实现一个定长的链表，这一点非常有用。 index 可以为负数，index=-1表示倒数第一个元素，同样index=-2表示倒数第二个元素。 &gt; rpush books python java golang(integer) 3&gt; lindex books 1 # O(n) 慎用&quot;java&quot;&gt; lrange books 0 -1 # 获取所有元素，O(n) 慎用1) &quot;python&quot;2) &quot;java&quot;3) &quot;golang&quot;&gt; ltrim books 1 -1 # O(n) 慎用OK&gt; lrange books 0 -11) &quot;java&quot;2) &quot;golang&quot;&gt; ltrim books 1 0 # 这其实是清空了整个列表，因为区间范围长度为负OK&gt; llen books(integer) 0 快速列表 如果再深入一点，你会发现 Redis 底层存储的还不是一个简单的 linkedlist，而是称之为快速链表 quicklist 的一个结构。 首先在列表元素较少的情况下会使用一块连续的内存存储，这个结构是 ziplist，也即是压缩列表。它将所有的元素紧挨着一起存储，分配的是一块连续的内存。当数据量比较多的时候才会改成 quicklist。因为普通的链表需要的附加指针空间太大，会比较浪费空间，而且会加重内存的碎片化。比如这个列表里存的只是 int 类型的数据，结构上还需要两个额外的指针 prev 和 next 。所以 Redis 将链表和 ziplist 结合起来组成了 quicklist。也就是将多个 ziplist 使用双向指针串起来使用。这样既满足了快速的插入删除性能，又不会出现太大的空间冗余。 关于列表的内部结构实现，请阅读第 34 节《极度深寒 —— 探索「压缩列表」内部》和第 35 节《极度深寒 —— 探索「快速列表」内部》 hash (字典)Redis 的字典相当于 Java 语言里面的 HashMap，它是无序字典。内部实现结构上同 Java 的 HashMap 也是一致的，同样的数组 + 链表二维结构。第一维 hash 的数组位置碰撞时，就会将碰撞的元素使用链表串接起来。 不同的是，Redis 的字典的值只能是字符串，另外它们 rehash 的方式不一样，因为 Java 的 HashMap 在字典很大时，rehash 是个耗时的操作，需要一次性全部 rehash。Redis 为了高性能，不能堵塞服务，所以采用了渐进式 rehash 策略。 渐进式 rehash 会在 rehash 的同时，保留新旧两个 hash 结构，查询时会同时查询两个 hash 结构，然后在后续的定时任务中以及 hash 操作指令中，循序渐进地将旧 hash 的内容一点点迁移到新的 hash 结构中。当搬迁完成了，就会使用新的hash结构取而代之。 当 hash 移除了最后一个元素之后，该数据结构自动被删除，内存被回收。 hash 结构也可以用来存储用户信息，不同于字符串一次性需要全部序列化整个对象，hash 可以对用户结构中的每个字段单独存储。这样当我们需要获取用户信息时可以进行部分获取。而以整个字符串的形式去保存用户信息的话就只能一次性全部读取，这样就会比较浪费网络流量。 hash 也有缺点，hash 结构的存储消耗要高于单个字符串，到底该使用 hash 还是字符串，需要根据实际情况再三权衡。 &gt; hset books java &quot;think in java&quot; # 命令行的字符串如果包含空格，要用引号括起来(integer) 1&gt; hset books golang &quot;concurrency in go&quot;(integer) 1&gt; hset books python &quot;python cookbook&quot;(integer) 1&gt; hgetall books # entries()，key 和 value 间隔出现1) &quot;java&quot;2) &quot;think in java&quot;3) &quot;golang&quot;4) &quot;concurrency in go&quot;5) &quot;python&quot;6) &quot;python cookbook&quot;&gt; hlen books(integer) 3&gt; hget books java&quot;think in java&quot;&gt; hset books golang &quot;learning go programming&quot; # 因为是更新操作，所以返回 0(integer) 0&gt; hget books golang&quot;learning go programming&quot;&gt; hmset books java &quot;effective java&quot; python &quot;learning python&quot; golang &quot;modern golang programming&quot; # 批量 setOK 同字符串对象一样，hash 结构中的单个子 key 也可以进行计数，它对应的指令是 hincrby，和 incr使用基本一样。 # 老钱又老了一岁&gt; hincrby user-laoqian age 1(integer) 30 关于字典的内部结构实现，请阅读第 33 节《极度深寒 —— 探索「字典」内部》。 set (集合)Redis 的集合相当于 Java 语言里面的 HashSet，它内部的键值对是无序的唯一的。它的内部实现相当于一个特殊的字典，字典中所有的 value 都是一个值NULL。 当集合中最后一个元素移除之后，数据结构自动删除，内存被回收。 set 结构可以用来存储活动中奖的用户 ID，因为有去重功能，可以保证同一个用户不会中奖两次。 &gt; sadd books python(integer) 1&gt; sadd books python # 重复(integer) 0&gt; sadd books java golang(integer) 2&gt; smembers books # 注意顺序，和插入的并不一致，因为 set 是无序的1) &quot;java&quot;2) &quot;python&quot;3) &quot;golang&quot;&gt; sismember books java # 查询某个 value 是否存在，相当于 contains(o)(integer) 1&gt; sismember books rust(integer) 0&gt; scard books # 获取长度相当于 count()(integer) 3&gt; spop books # 弹出一个&quot;java&quot; zset (有序集合)zset 可能是 Redis 提供的最为特色的数据结构，它也是在面试中面试官最爱问的数据结构。它类似于 Java 的 SortedSet 和 HashMap 的结合体，一方面它是一个 set，保证了内部 value 的唯一性，另一方面它可以给每个 value 赋予一个 score，代表这个 value 的排序权重。它的内部实现用的是一种叫做「跳跃列表」的数据结构。 zset 中最后一个 value 被移除后，数据结构自动删除，内存被回收。 zset 可以用来存粉丝列表，value 值是粉丝的用户 ID，score 是关注时间。我们可以对粉丝列表按关注时间进行排序。 zset 还可以用来存储学生的成绩，value 值是学生的 ID，score 是他的考试成绩。我们可以对成绩按分数进行排序就可以得到他的名次。 &gt; zadd books 9.0 &quot;think in java&quot;(integer) 1&gt; zadd books 8.9 &quot;java concurrency&quot;(integer) 1&gt; zadd books 8.6 &quot;java cookbook&quot;(integer) 1&gt; zrange books 0 -1 # 按 score 排序列出，参数区间为排名范围1) &quot;java cookbook&quot;2) &quot;java concurrency&quot;3) &quot;think in java&quot;&gt; zrevrange books 0 -1 # 按 score 逆序列出，参数区间为排名范围1) &quot;think in java&quot;2) &quot;java concurrency&quot;3) &quot;java cookbook&quot;&gt; zcard books # 相当于 count()(integer) 3&gt; zscore books &quot;java concurrency&quot; # 获取指定 value 的 score&quot;8.9000000000000004&quot; # 内部 score 使用 double 类型进行存储，所以存在小数点精度问题&gt; zrank books &quot;java concurrency&quot; # 排名(integer) 1&gt; zrangebyscore books 0 8.91 # 根据分值区间遍历 zset1) &quot;java cookbook&quot;2) &quot;java concurrency&quot;&gt; zrangebyscore books -inf 8.91 withscores # 根据分值区间 (-∞, 8.91] 遍历 zset，同时返回分值。inf 代表 infinite，无穷大的意思。1) &quot;java cookbook&quot;2) &quot;8.5999999999999996&quot;3) &quot;java concurrency&quot;4) &quot;8.9000000000000004&quot;&gt; zrem books &quot;java concurrency&quot; # 删除 value(integer) 1&gt; zrange books 0 -11) &quot;java cookbook&quot;2) &quot;think in java&quot; 跳跃列表 zset 内部的排序功能是通过「跳跃列表」数据结构来实现的，它的结构非常特殊，也比较复杂。 因为 zset 要支持随机的插入和删除，所以它不好使用数组来表示。我们先看一个普通的链表结构。 我们需要这个链表按照 score 值进行排序。这意味着当有新元素需要插入时，要定位到特定位置的插入点，这样才可以继续保证链表是有序的。通常我们会通过二分查找来找到插入点，但是二分查找的对象必须是数组，只有数组才可以支持快速位置定位，链表做不到，那该怎么办？ 想想一个创业公司，刚开始只有几个人，团队成员之间人人平等，都是联合创始人。随着公司的成长，人数渐渐变多，团队沟通成本随之增加。这时候就会引入组长制，对团队进行划分。每个团队会有一个组长。开会的时候分团队进行，多个组长之间还会有自己的会议安排。公司规模进一步扩展，需要再增加一个层级 —— 部门，每个部门会从组长列表中推选出一个代表来作为部长。部长们之间还会有自己的高层会议安排。 跳跃列表就是类似于这种层级制，最下面一层所有的元素都会串起来。然后每隔几个元素挑选出一个代表来，再将这几个代表使用另外一级指针串起来。然后在这些代表里再挑出二级代表，再串起来。最终就形成了金字塔结构。 想想你老家在世界地图中的位置：亚洲–&gt;中国-&gt;安徽省-&gt;安庆市-&gt;枞阳县-&gt;汤沟镇-&gt;田间村-&gt;xxxx号，也是这样一个类似的结构。 「跳跃列表」之所以「跳跃」，是因为内部的元素可能「身兼数职」，比如上图中间的这个元素，同时处于 L0、L1 和 L2 层，可以快速在不同层次之间进行「跳跃」。 定位插入点时，先在顶层进行定位，然后下潜到下一级定位，一直下潜到最底层找到合适的位置，将新元素插进去。你也许会问，那新插入的元素如何才有机会「身兼数职」呢？ 跳跃列表采取一个随机策略来决定新元素可以兼职到第几层。 首先 L0 层肯定是 100% 了，L1 层只有 50% 的概率，L2 层只有 25% 的概率，L3 层只有 12.5% 的概率，一直随机到最顶层 L31 层。绝大多数元素都过不了几层，只有极少数元素可以深入到顶层。列表中的元素越多，能够深入的层次就越深，能进入到顶层的概率就会越大。 这还挺公平的，能不能进入中央不是靠拼爹，而是看运气。 关于跳跃列表的内部结构实现，请阅读第 36 节《极度深寒 —— 探索「跳跃列表」内部结构》 容器型数据结构的通用规则list/set/hash/zset 这四种数据结构是容器型数据结构，它们共享下面两条通用规则： create if not exists 如果容器不存在，那就创建一个，再进行操作。比如 rpush 操作刚开始是没有列表的，Redis 就会自动创建一个，然后再 rpush 进去新元素。 drop if no elements 如果容器里元素没有了，那么立即删除元素，释放内存。这意味着 lpop 操作到最后一个元素，列表就消失了。 过期时间Redis 所有的数据结构都可以设置过期时间，时间到了，Redis 会自动删除相应的对象。需要注意的是过期是以对象为单位，比如一个 hash 结构的过期是整个 hash 对象的过期，而不是其中的某个子 key。 还有一个需要特别注意的地方是如果一个字符串已经设置了过期时间，然后你调用了 set 方法修改了它，它的过期时间会消失。 127.0.0.1:6379&gt; set codehole yoyoOK127.0.0.1:6379&gt; expire codehole 600(integer) 1127.0.0.1:6379&gt; ttl codehole(integer) 597127.0.0.1:6379&gt; set codehole yoyoOK127.0.0.1:6379&gt; ttl codehole(integer) -1 思考 &amp; 作业 如果你是 Java 用户，请定义一个用户信息结构体，然后使用 fastjson 对用户信息对象进行序列化和反序列化，再使用 Jedis 对 Redis 缓存的用户信息进行存和取。 如果你是 Python 用户，使用内置的 JSON 包就可以了。然后通过 redis-py 来对 Redis 缓存的用户信息进行存和取。 想想如果要改成用 hash 结构来缓存用户信息，你该如何封装比较合适？ 想想平时还有哪些指令你平时用过而本小节没有提到的？ 回想一下掘金社区的功能模块中分别会使用到哪些数据结构？ 扩展阅读 《存结构体信息到底该使用 hash 还是 string？》","tags":[{"name":"redis","slug":"redis","permalink":"https://yapengren.github.io/tags/redis/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"redis","slug":"技术分享/redis","permalink":"https://yapengren.github.io/categories/技术分享/redis/"}]},{"title":"HashMap 源码分析","date":"2019-08-17T05:45:12.000Z","path":"wiki/HashMap-源码分析/","text":"继承体系 在 Java 中，HashMap 的实现采用了（数组 + 链表 + 红黑树）的复杂结构，数组的一个元素又称作桶。 在添加元素时，会根据 hash 值算出元素在数组中的位置，如果该位置没有元素，则直接把元素放置在此处，如果该位置有元素了，则把元素以链表的形式放置在链表的尾部。 当一个链表的元素个数达到一定的数量（且数组的长度达到一定的长度）后，则把链表转化为红黑树，从而提高效率。 数组的查询效率为 O(1)，链表的查询效率是 O(k)，红黑树的查询效率是 O(log k)，k为桶中的元素个数，所以当元素数量非常多的时候，转化为红黑树能极大地提高效率。 源码分析属性/** * 默认初始容量为 16 */static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4;/** * 最大容量为 2 的 30 次方 */static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;/** * 默认装载因子 */static final float DEFAULT_LOAD_FACTOR = 0.75f;/** * 当一个桶中的元素 ≥ 8 时进行树化 */static final int TREEIFY_THRESHOLD = 8;/** * 当一个桶中的元素 ≤ 6 时把树转换成链表 */static final int UNTREEIFY_THRESHOLD = 6;/** * 当桶的个数达到 64 的时候进行树化 */static final int MIN_TREEIFY_CAPACITY = 64;/** * 数组，又叫做桶 */transient Node&lt;K, V&gt;[] table;/** * 作为 enterSet() 的缓存 */transient Set&lt;Map.Entry&lt;K, V&gt;&gt; entrySet;/** * 元素的数量 */transient int size;/** * 修改次数，用于在迭代的时候执行快速失败策略 */transient int modCount;/** * 当桶的使用数量达到多少时进行扩容，threshold = capacity * loadFactor */int threshold;/** * 装载因子 */final float loadFactor; put(K key, V value) 方法public V put(K key, V value) &#123; // 调用 hash(key) 计算出 key 的 hash 值 return putVal(hash(key), key, value, false, true);&#125;static final int hash(Object key) &#123; int h; // 如果 key 为 null，则 hash 值为0，否则调用 key 的 hashCode() 方法 // 并让高 16 位与整个 hash 异或，这样做是为了使计算出的 hash 更分散 return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125;final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; // 如果桶的数量为 0，则初始化 if ((tab = table) == null || (n = tab.length) == 0) // 调用 resize() 初始化 n = (tab = resize()).length; // (n-1) &amp; hash 计算元素在哪个桶中 // 如果这个桶中还没有元素，则把这个元素放在桶中的第一个位置 if ((p = tab[i = (n - 1) &amp; hash]) == null) // 新建一个节点放在桶中 tab[i] = newNode(hash, key, value, null); else &#123; // 如果桶中已经有元素存在了 Node&lt;K,V&gt; e; K k; // 如果桶中第一个元素的 key 与待插入元素的 key 相同，保存到 e 中用于后续修改 value 值 if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; else if (p instanceof TreeNode) // 如果第一个元素是树节点，则调用树节点的 putTreeVal 插入元素 e = ((HashMap.TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; // 遍历这个桶对应的链表，binCount 用于存储链表中元素的个数 for (int binCount = 0; ; ++binCount) &#123; // 如果链表遍历完了都没有找到相同 key 的元素，则 key 对应的元素不存在，则在链表最后插入一个新节点 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); // 如果插入新节点后链表长度 &gt; 8，则判断是否需要树化，因为第一个元素没有加到 binCount 中，所以 -1 if (binCount &gt;= TREEIFY_THRESHOLD - 1) treeifyBin(tab, hash); break; &#125; // 如果待插入的 key 在链表中找到了，则退出循环 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; // 如果找到了对应 key 的元素 if (e != null) &#123; // existing mapping for key // 记录下旧值 V oldValue = e.value; // 判断是否需要替换旧值 if (!onlyIfAbsent || oldValue == null) // 替换旧值为新值 e.value = value; afterNodeAccess(e); // 返回旧值 return oldValue; &#125; &#125; // 到这里了说明没有找到元素 // 修改次数 +1 ++modCount; // 元素数量 +1，判断是否需要扩容 if (++size &gt; threshold) // 扩容 resize(); afterNodeInsertion(evict); // 没有找到元素返回 null return null;&#125; 计算 key 的 hash 值； 如果桶（数组）数量为 0，则初始化桶； 如果 key 所在的桶没有元素，则直接插入； 如果 key 所在的桶中的第一个元素的 key 与待插入的key相同，说明找到了元素，转后续流程（9）处理； 如果第一个元素是树节点，则调用树节点的 putTreeVal() 寻找元素或插入树节点； 如果不是以上三种情况，则遍历桶对应的链表查找 key 是否存在于链表中； 如果找到了对应 key 的元素，则转后续流程（9）处理； 如果没找到对应 key 的元素，则在链表最后插入一个新节点并判断是否需要树化； 如果找到了对应 key 的元素，则判断是否需要替换旧值，并直接返回旧值； 如果插入了元素，则数量加 1 并判断是否需要扩容；","tags":[{"name":"java","slug":"java","permalink":"https://yapengren.github.io/tags/java/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"java基础","slug":"技术分享/java基础","permalink":"https://yapengren.github.io/categories/技术分享/java基础/"}]},{"title":"ArrayList 源码分析","date":"2019-08-17T02:28:42.000Z","path":"wiki/ArrayList-源码分析/","text":"继承体系 源码分析属性/** * 默认容量为10，也就是通过 new ArrayList() 创建时的默认容量 */private static final int DEFAULT_CAPACITY = 10;/** * 空数组 * 这种是通过 new ArrayList(0) 创建时用的空数组 */private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;;/** * 空数组 * 这种是通过 new ArrayList() 创建时用的空数组 * 与 EMPTY_ELEMENTDATA 的区别是在添加第一个元素时使用这个空数组会初始化为 DEFAULT_CAPACITY（10）个元素 */private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;/** * 真正存放元素的地方 * 使用 transient 关键字能不序列化这个字段 */transient Object[] elementData; // non-private to simplify nested class access/** * 真正存放元素的个数 */private int size; ArrayList(int initialCapacity) 构造方法public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; // 如果传入的初始容量 &gt; 0，新建一个数组存储元素 this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; // 如果传入的初始容量 = 0，使用空数组 EMPTY_ELEMENTDATA this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; // 如果传入的初始容量 &lt; 0，抛出异常 throw new IllegalArgumentException(\"Illegal Capacity: \"+ initialCapacity); &#125;&#125; add(E e) 方法添加元素到末尾 public boolean add(E e) &#123; // 检查是否需要扩容 ensureCapacityInternal(size + 1); // 将元素插入到最后一位 elementData[size++] = e; return true;&#125;private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; // 如果是空数组 DEFAULTCAPACITY_EMPTY_ELEMENTDATA，就初始化为默认大小 10 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; if (minCapacity - elementData.length &gt; 0) // 扩容 grow(minCapacity);&#125;/** * 扩容 * */private void grow(int minCapacity) &#123; int oldCapacity = elementData.length; // 新容量为旧容量的 1.5 倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); // 如果新容量发现比需要的容量还小，则以需要的容量为准 if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; // 如果新容量已经超过最大容量了，则使用最大容量 if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // 以新容量拷贝出来一个新数组 elementData = Arrays.copyOf(elementData, newCapacity);&#125; 检查是否需要扩容； 如果 elementData 等于 DEFAULTCAPACITY_EMPTY_ELEMENTDATA，则初始化容量大小为 DEFAULT_CAPACITY； 新容量是老容量的1.5 倍（oldCapacity + (oldCapacity &gt;&gt; 1)），如果加了这么多容量发现比需要的容量还小，则以需要的容量为； 创建新容量的数组并把老数组拷贝到新数组；","tags":[{"name":"java","slug":"java","permalink":"https://yapengren.github.io/tags/java/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"java基础","slug":"技术分享/java基础","permalink":"https://yapengren.github.io/categories/技术分享/java基础/"}]},{"title":"Dubbo 知识点","date":"2019-08-15T08:54:12.000Z","path":"wiki/Dubbo-知识点/","text":"302","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://yapengren.github.io/tags/dubbo/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"dubbo","slug":"技术分享/dubbo","permalink":"https://yapengren.github.io/categories/技术分享/dubbo/"}]},{"title":"Mybatis 知识点","date":"2019-08-14T09:20:15.000Z","path":"wiki/Mybatis-知识点/","text":"MyBatis 中 resultType 和 resultMap 的区别","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://yapengren.github.io/tags/mybatis/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"mybatis","slug":"技术分享/mybatis","permalink":"https://yapengren.github.io/categories/技术分享/mybatis/"}]},{"title":"synchronized 和 lock 有什么区别？用新的lock有什么好处？举例说说","date":"2019-08-04T06:32:36.000Z","path":"wiki/synchronized-和-lock-有什么区别？用新的lock有什么好处？举例说说/","text":"原始构成 synchronized 是关键字，属于JVM层面 monitorenter（底层是通过 monitor 对象来完成，其实 wait/notify 等方法也依赖于 monitor 对象只有在同步块或者方法中才能调用 wait/notify 等方法） monitorexit Lock 是具体类（java.util.concurrent.locks.lock）是api层面的锁 使用方法 synchronized 不需要用户去手动释放锁，当synchronized代码执行完后系统会自动让线程释放对锁的占用。 ReentrantLock 则需要用户去手动释放锁，若没有主动释放锁，就有可能导致出现死锁现象。需要 lock() 和unlock() 方法配合 try/finally 语句块来完成。 等待是否可中断 synchronized 不可中断，除非抛出异常或者正常运行完成。 ReentrantLock可中断 1.设置超时方法 tryLock(long timeout,TimeUnit unit) 2.lockInterruptibly()放代码块中，调用interrupt()方法可中断 加锁是否公平 synchronized 非公平锁 ReentrantLock 两者都可以，默认非公平锁，构造方法可以传入 boolean 值，true为公平锁，false为非公平锁 锁绑定多个条件 Condition synchronized 没有 ReentrantLock 用来实现分组唤醒需要唤醒的线程，可以精确唤醒，而不是像 synchronized 要么随机唤醒一个要么唤醒全部线程。 举例：锁绑定多个条件 Condition/** * * 题目：多线程之间按顺序调用，实现A-&gt;B-&gt;C三个线程启动，要求如下： * A打印5次，B打印10次，C打印15次 * 紧接着 * A打印5次，B打印10次，C打印15次 * 打印10轮 */public class SyncAndReentrantLockdemo &#123; public static void main(String[] args) &#123; ShareResource shareResource = new ShareResource(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; shareResource.print5(); &#125; &#125;, \"A\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; shareResource.print10(); &#125; &#125;, \"B\").start(); new Thread(() -&gt; &#123; for (int i = 0; i &lt; 10; i++) &#123; shareResource.print15(); &#125; &#125;, \"C\").start(); &#125;&#125;class ShareResource &#123; private int number = 1; private Lock lock = new ReentrantLock(); private Condition c1 = lock.newCondition(); private Condition c2 = lock.newCondition(); private Condition c3 = lock.newCondition(); public void print5() &#123; lock.lock(); try &#123; // 1判断 while (number != 1) &#123; c1.await(); &#125; // 2干活 for (int i = 0; i &lt; 5; i++) &#123; System.out.println(Thread.currentThread().getName() + \" \" + i); &#125; // 3通知 number = 2; c2.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void print10() &#123; lock.lock(); try &#123; // 1判断 while (number != 2) &#123; c2.await(); &#125; // 2干活 for (int i = 0; i &lt; 10; i++) &#123; System.out.println(Thread.currentThread().getName() + \" \" + i); &#125; // 3通知 number = 3; c3.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void print15() &#123; lock.lock(); try &#123; // 1判断 while (number != 3) &#123; c3.await(); &#125; // 2干活 for (int i = 0; i &lt; 5; i++) &#123; System.out.println(Thread.currentThread().getName() + \" \" + i); &#125; // 3通知 number = 1; c1.signal(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;","tags":[{"name":"java并发","slug":"java并发","permalink":"https://yapengren.github.io/tags/java并发/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"java并发","slug":"技术分享/java并发","permalink":"https://yapengren.github.io/categories/技术分享/java并发/"}]},{"title":"java hash 原理","date":"2019-08-04T05:23:50.000Z","path":"wiki/java-hash-原理/","text":"","tags":[{"name":"java","slug":"java","permalink":"https://yapengren.github.io/tags/java/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"java基础","slug":"技术分享/java基础","permalink":"https://yapengren.github.io/categories/技术分享/java基础/"}]},{"title":"让我们同步进阶","date":"2019-08-04T05:18:18.000Z","path":"wiki/让我们同步进阶/","text":"基础知识点Java技术驿站 CS-Notes JavaGuide 架构知识点互联网 java 工程师进阶知识完全扫盲 spring boot &amp; cloudSpring Cloud 程序猿DD","tags":[],"categories":[]},{"title":"redis 知识点","date":"2019-08-04T05:12:21.000Z","path":"wiki/redis-知识点/","text":"Redis用过哪些数据数据，以及Redis底层怎么实现string, hash, list, set, zset Redis缓存穿透，缓存雪崩如何使用Redis来实现分布式锁Redis的并发竞争问题如何解决Redis持久化的几种方式，优缺点是什么，怎么实现的aof 文件太大会怎么样Redis的缓存失效策略 &amp; 最大缓存策略Redis集群，高可用，原理Redis缓存分片Redis的数据淘汰策略","tags":[{"name":"redis","slug":"redis","permalink":"https://yapengren.github.io/tags/redis/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"redis","slug":"技术分享/redis","permalink":"https://yapengren.github.io/categories/技术分享/redis/"}]},{"title":"Spring 知识点","date":"2019-08-04T05:01:51.000Z","path":"wiki/Spring-知识点/","text":"BeanFactory 和 FactoryBean？Spring IOC 的理解，其初始化过程？BeanFactory 和 ApplicationContext？Spring Bean 的生命周期，如何被管理的？Spring Bean 的加载过程是怎样的？如果要你实现Spring AOP，请问怎么实现？如果要你实现Spring IOC，你会注意哪些问题？Spring 是如何管理事务的，事务管理机制？Spring 的不同事务传播行为有哪些，干什么用的？Spring 中用到了那些设计模式？Spring MVC 的工作原理？Spring 循环注入的原理？Spring AOP的理解，各个术语，他们是怎么相互工作的？Spring 如何保证 Controller 并发的安全？","tags":[{"name":"spring","slug":"spring","permalink":"https://yapengren.github.io/tags/spring/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"spring","slug":"技术分享/spring","permalink":"https://yapengren.github.io/categories/技术分享/spring/"}]},{"title":"FastDFS 流程图","date":"2019-08-04T03:34:10.000Z","path":"wiki/FastDFS-流程图/","text":"FastDFS 执行流程FastDFS 服务端有三个角色：跟踪服务器（Tracker Server）、存储服务器（Storage Server）和客户端（Client）。 Tracker Server：跟踪服务器，主要做调度工作，起负载均衡的作用。在内存记录集群中所有存储组和存储服务器的状态信息，是客户端和数据服务器交互的枢纽。相比 GFS 中的 Master 更为精简，不记录文件索引信息，占用的内存量很少。 Storage Server：存储服务器（又称存储节点或数据服务器），文件和文件属性（Meta Data）都保存到存储服务器上。Storage Server 直接利用 OS 的文件系统调用管理文件。 Client：客户端，作为业务请求的发起方，通过专有接口，使用 TCP/IP 协议与跟踪器服务器或存储节点进行数据交互。FastDFS 向使用者提供基本文件访问接口，如 upload、download、append、delete 等，以客户端库的方式提供给用户使用。 通过一张图来看一下 FastDFS 的运行机制： Tracker 相当于 FastDFS 的大脑，不论是上传还是下载都是通过 Tracker 来分配资源；客户端一般可以使用 Ngnix 等静态服务器来调用或者做一部分的缓存；存储服务器内部分为卷（或者叫做组），卷与卷之间是平行的关系，可以根据资源的使用情况随时增加，卷内服务器文件相互同步备份，以达到容灾的目的。 上传机制首先客户端请求 Tracker 服务获取到存储服务器的 IP 地址和端口，然后客户端根据返回的 IP 地址和端口号请求上传文件，存储服务器接收到请求后生产文件，并且将文件内容写入磁盘并返回给客户端 file_id、路径信息、文件名等信息，客户端保存相关信息上传完毕。 下载机制客户端带上文件名信息请求 Tracker 服务获取到存储服务器的 IP 地址和端口，然后客户端根据返回的 IP 地址和端口号请求下载文件，存储服务器接收到请求后返回文件给客户端。","tags":[{"name":"FastDFS","slug":"FastDFS","permalink":"https://yapengren.github.io/tags/FastDFS/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"文件存储","slug":"技术分享/文件存储","permalink":"https://yapengren.github.io/categories/技术分享/文件存储/"}]},{"title":"springMVC 流程图","date":"2019-08-04T03:30:24.000Z","path":"wiki/springMVC-流程图/","text":"springMVC执行流程 用户发送请求至前端控制器 DispatcherServlet 前端控制器 DispatcherServlet 收到请求调用处理器映射器HandlerMapping。 处理器映射器 HandlerMapping 根据请求 url 找到具体的处理器，生成处理器对象及处理器拦截器一并返回给前端控制器DispatcherServlet。 前端控制器 DispatcherServlet 通过处理器适配器 HandlerAdapter 调用处理器 执行处理器，执行业务逻辑(Controller，也叫后端控制器)。 Controller 执行完成返回 ModelAndView 处理器适配器 HandlerAdapter 将 controller 执行结果 ModelAndView 返回给前端控制器 DispatcherServlet 前端控制器 DispatcherServlet 将 ModelAndView 传给视图解析器 ViewResolver 视图解析器 ViewResolver 解析后返回具体 View DispatcherServlet 对 View 进行渲染视图（即将模型数据填充至视图中）。 DispatcherServlet 响应用户","tags":[{"name":"spring","slug":"spring","permalink":"https://yapengren.github.io/tags/spring/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"spring","slug":"技术分享/spring","permalink":"https://yapengren.github.io/categories/技术分享/spring/"}]},{"title":"shiro 流程图","date":"2019-08-04T03:28:49.000Z","path":"wiki/shiro-流程图/","text":"","tags":[{"name":"shiro","slug":"shiro","permalink":"https://yapengren.github.io/tags/shiro/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"权限认证","slug":"技术分享/权限认证","permalink":"https://yapengren.github.io/categories/技术分享/权限认证/"}]},{"title":"Mybatis 架构图","date":"2019-08-04T03:21:42.000Z","path":"wiki/Mybatis-架构图/","text":"mybatis配置 SqlMapConfig.xml，此文件作为 mybatis 的全局配置文件，配置了 mybatis 的运行环境等信息。 mapper.xml 文件即sql映射文件，文件中配置了操作数据库的 sql 语句。此文件需要在 SqlMapConfig.xml 中加载。 通过 mybatis 环境等配置信息构造 SqlSessionFactory 即会话工厂 由会话工厂创建 sqlSession 即会话，操作数据库需要通过 sqlSession 进行。 mybatis 底层自定义了 Executor 执行器接口操作数据库，Executor 接口有两个实现，一个是基本执行器、一个是缓存执行器。 Mapped Statement 也是 mybatis 一个底层封装对象，它包装了 mybatis 配置信息及 sql 映射信息等。mapper.xml 文件中一个 sql 对应一个 Mapped Statement 对象，sql 的 id 即是 Mapped statement 的id。 Mapped Statement 对 sql 执行输入参数进行定义，包括 HashMap、基本类型、pojo，Executor 通过Mapped Statement 在执行 sql前将输入的 java 对象映射至 sql 中，输入参数映射就是 jdbc 编程中对preparedStatement 设置参数。 Mapped Statement 对 sql 执行输出结果进行定义，包括 HashMap、基本类型、pojo，Executor 通过Mapped Statement 在执行 sql 后将输出结果映射至 java 对象中，输出结果映射过程相当于 jdbc 编程中对结果的解析处理过程。","tags":[{"name":"mybatis","slug":"mybatis","permalink":"https://yapengren.github.io/tags/mybatis/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"mybatis","slug":"技术分享/mybatis","permalink":"https://yapengren.github.io/categories/技术分享/mybatis/"}]},{"title":"Dubbo 架构","date":"2019-08-04T03:15:00.000Z","path":"wiki/Dubbo-架构/","text":"节点角色说明 节点 角色说明 Provider 暴露服务的服务提供方 Consumer 调用远程服务的服务消费方 Registry 服务注册与发现的注册中心 Monitor 统计服务的调用次数和调用时间的监控中心 Container 服务运行容器 调用关系说明 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 参考http://dubbo.apache.org/zh-cn/docs/user/preface/architecture.html","tags":[{"name":"dubbo","slug":"dubbo","permalink":"https://yapengren.github.io/tags/dubbo/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"dubbo","slug":"技术分享/dubbo","permalink":"https://yapengren.github.io/categories/技术分享/dubbo/"}]},{"title":"Java 基础知识点","date":"2019-08-03T10:01:30.000Z","path":"wiki/Java-基础知识点/","text":"List 和 Set 的区别HashSet 是如何保证不重复的HashMap 是线程安全的吗，为什么不是线程安全的（最好画图说明多线程环境下不安全）HashMap 的扩容过程HashMap 1.7 与 1.8 的 区别，说明 1.8 做了哪些优化，如何优化的？final finally finalize强引用 、软引用、 弱引用、虚引用Java反射Arrays.sort 实现原理和 Collection 实现原理LinkedHashMap的应用cloneable接口实现原理异常分类以及处理机制wait和sleep的区别数组在内存中如何分配","tags":[{"name":"java","slug":"java","permalink":"https://yapengren.github.io/tags/java/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"java基础","slug":"技术分享/java基础","permalink":"https://yapengren.github.io/categories/技术分享/java基础/"}]},{"title":"MySQL 知识点","date":"2019-08-03T09:36:37.000Z","path":"wiki/MySQL-知识点/","text":"数据库MySQL 索引类型sql 优化的几种方式数据库事务数据库事务的 4 种隔离级别数据库事务的 4 个基本特性SQLMySQL 中FIND_IN_SET()和IN区别简析MySQL Explain详解MySQL中concat以及group_concat的使用MySQL中order by语句对null字段的排序SQL练习MySQL经典练习题及答案，常用SQL语句练习50题","tags":[{"name":"mysql","slug":"mysql","permalink":"https://yapengren.github.io/tags/mysql/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"数据库","slug":"技术分享/数据库","permalink":"https://yapengren.github.io/categories/技术分享/数据库/"}]},{"title":"intellij idea 修改记录","date":"2019-08-02T10:13:00.000Z","path":"wiki/intellij-idea-修改记录/","text":"过滤文件 显示多 Tabs","tags":[{"name":"util","slug":"util","permalink":"https://yapengren.github.io/tags/util/"}],"categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://yapengren.github.io/categories/开发工具/"},{"name":"IDE","slug":"开发工具/IDE","permalink":"https://yapengren.github.io/categories/开发工具/IDE/"}]},{"title":"mac brew 服务","date":"2019-08-02T09:40:48.000Z","path":"wiki/mac-brew-服务/","text":"brew 常用命令brew 搜索软件brew search nginxbrew 安装软件brew install nginxbrew 卸载软件brew uninstall nginxbrew 升级sudo brew update查看安装信息sudo brew info nginx 查看已安装软件brew list brew 安装nginx安装sudo brew install nginx启动sudo brew services start nginx重启sudo brew services restart nginx停止sudo brew services stop nginx查看cat /usr/local/etc/nginx/nignx.conf brew redis启动redis-server /usr/local/etc/redis-6379.conf停止redis-cli -p 6379 shutdown brew 安装 activemq安装brew install activemq查看版本activemq —version启动activemq start地址http://localhost:8161 admin admin brew 安装 rabbitmq安装brew install rabbitmq启动brew services start rabbitmq地址http://localhost:15672 guest guest brew 安装 mongodb参考：https://blog.csdn.net/ligh_sqh/article/details/81112428 mongo启动 mongodb 客户端cd ~/software/adminmongonpm start客户端地址 http://localhost:1234 nacos 启动命令sh ～/software/nacos/bin/startup.sh -m standalone elasticsearch-head 安装和启动 -elasticsearch GUI客户端git clone git://github.com/mobz/elasticsearch-head.gitcd elasticsearch-headnpm installnpm run starthttp://localhost:9100","tags":[{"name":"mac","slug":"mac","permalink":"https://yapengren.github.io/tags/mac/"}],"categories":[{"name":"系统方面","slug":"系统方面","permalink":"https://yapengren.github.io/categories/系统方面/"},{"name":"mac","slug":"系统方面/mac","permalink":"https://yapengren.github.io/categories/系统方面/mac/"}]},{"title":"token 防表单重复提交","date":"2019-08-02T03:16:10.000Z","path":"wiki/token-防表单重复提交/","text":"生成 token加载页面时候调用 initToken() 方法，生成 token 存入页面隐藏域中 &lt;%--隐藏域-防止表单的重复提交--%&gt;&lt;input type=&quot;hidden&quot; name=&quot;examToken&quot; id=&quot;examToken&quot;&gt;&lt;/input&gt; 表单提交表单提交的时候带上 token 方法添加注解springMVC 方法上添加注解 @TokenCheck(isCheckToken = true) 自定义注解自定义注解 TokenCheck.java // 注解会在class字节码文件中存在，在运行时可以通过反射获取到@Retention(RetentionPolicy.RUNTIME) // 定义注解的作用目标**作用范围字段、枚举的常量/方法@Target(&#123;ElementType.METHOD&#125;)// 说明该注解将被包含在javadoc中@Documentedpublic @interface TokenCheck &#123; /** * 是否需要校验 */ boolean isCheckToken() default false;&#125; 自定义注解拦截器springMVC 配置文件 spring-servlet.xml 添加 &lt;mvc:interceptors 拦截器 &lt;mvc:interceptors&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path=\"/**\" /&gt; &lt;bean class=\"com.ycx.exam.web.comm.interceptor.TokenCheckDuplicateSubmitInterceptor\"&gt;&lt;/bean&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 拦截器内容TokenCheckDuplicateSubmitInterceptor.java 在拦截器中判断TokenCheck注解isCheckToken是否为 true，如果为 true，则执行缓存校验； 先从 redis 缓存中获取到 token 集合，再从缓存中查询 token； 如果存在，则属于重复提交，返回； 如果不存在，则属于首次提交，将此token压入token集合中并将token集合放回redis中； public class TokenCheckDuplicateSubmitInterceptor extends HandlerInterceptorAdapter &#123; private static final Logger log = Logger.getLogger(TokenCheckDuplicateSubmitInterceptor.class); @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123;&#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123;&#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) &#123; WebApplicationContext context = WebApplicationContextUtils.getRequiredWebApplicationContext(request.getServletContext()); CacheService cacheService = (CacheService) context.getBean(\"cacheService\"); if (cacheService == null) &#123; log.warn(\"token拦截器校验重复提交，缓存service为空!\"); return true; &#125; if (handler instanceof HandlerMethod) &#123; HandlerMethod handlerMethod = (HandlerMethod) handler; Method method = handlerMethod.getMethod(); TokenCheck annotation = method.getAnnotation(TokenCheck.class); if (annotation != null) &#123; boolean isCheckToken = annotation.isCheckToken(); if (isCheckToken) &#123; boolean isExist = true; boolean isgetLock = getLock(cacheService, \"examTokenLock\", 1); if (isgetLock) &#123; isExist = checkTokenExist(request, cacheService); if (!isExist) &#123; log.warn(\"token拦截重复提交校验\" + method.getName() + \"重复提交!\"); &#125; &#125; cacheService.releaseLock(\"examTokenLock\"); return isExist; &#125; &#125; &#125; else &#123; try &#123; return super.preHandle(request, response, handler); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; return true; &#125; /** * @param cacheService * @param cacheKey * @param second 秒 * @return */ private boolean getLock(CacheService cacheService, String cacheKey, long second) &#123; boolean isgetLock = cacheService.getLock(cacheKey, \"1\", second); //如果没有获得锁，将默认进行三次锁的获取 if (!isgetLock) &#123; log.info(\"获得分布式锁失败，进入等待...........\"); for (int i = 0; i &lt;= 2; i++) &#123; isgetLock = cacheService.getLock(cacheKey, \"1\", second); try &#123; if (!isgetLock) &#123; Thread.sleep(1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (isgetLock) &#123; break; &#125; &#125; &#125; return isgetLock; &#125; /** * 缓存校验 * * @param request * @param cacheService * @return */ private boolean checkTokenExist(HttpServletRequest request, CacheService cacheService) &#123; String token = request.getParameter(\"examToken\"); if (StringUtils.isEmpty(token)) &#123; log.warn(\"token拦截器校验重复提交，页面提交过来token为空!\"); return true; &#125; token = token.trim(); LRULinkedHashMap&lt;String, String&gt; cmap = (LRULinkedHashMap&lt;String, String&gt;) cacheService.getCacheData(\"examTokenMap\"); if (cmap == null) &#123; int size = 131072; // 最近最少使用算法，linkedHashMap实现，主要是针对缓存过期策略实现 cmap = new LRULinkedHashMap&lt;String, String&gt;(size); &#125; else &#123; log.info(\"token缓存map存在，size=\" + cmap.size()); &#125; String ieExist = cmap.get(token); if (StringUtils.isEmpty(ieExist)) &#123; log.info(\"缓存不存在token=\" + token); String valu = cmap.put(token, \"1\"); cacheService.setCacheDataForType(\"examTokenMap\", cmap, 1, TimeUnit.HOURS); log.info(\"将token=\" + token + \"加入缓存成功!\"); return true; &#125; else &#123; log.info(\"将token=\" + token + \"已经存在，重复提交!\"); return false; &#125; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://yapengren.github.io/tags/java/"}],"categories":[{"name":"技术分享","slug":"技术分享","permalink":"https://yapengren.github.io/categories/技术分享/"},{"name":"解决方案","slug":"技术分享/解决方案","permalink":"https://yapengren.github.io/categories/技术分享/解决方案/"}]}]}